{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Read PDF document and extract the text from a range of pages.\n",
    "def extract_text_from_pdf(pdf_path, start_page=None, end_page=None):\n",
    "    return extract_text(pdf_path, page_numbers=range(start_page, end_page+1) if start_page and end_page else None)\n",
    "\n",
    "# Usage\n",
    "pdf_path = '../data/CACM\\'18_Search-based_Program_Synthesis.pdf'\n",
    "extracted_text = extract_text_from_pdf(pdf_path, 1, 8)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from transformers import pipeline\n",
    "\n",
    "# Read PDF document and extract the text from a range of pages.\n",
    "def extract_text_from_pdf(pdf_path, start_page=None, end_page=None):\n",
    "    return extract_text(pdf_path, page_numbers=range(start_page, end_page+1) if start_page and end_page else None)\n",
    "\n",
    "# Usage\n",
    "pdf_path = '../data/CACM\\'18_Search-based_Program_Synthesis.pdf'\n",
    "extracted_text = extract_text_from_pdf(pdf_path, 1, 8)\n",
    "# Initialize the HuggingFace summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "# Run summarization\n",
    "summary = summarizer(extracted_text[0:3200], max_length=200, min_length=100, do_sample=False)\n",
    "# Print summary\n",
    "print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "340976a798ca0b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_bbc\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/roberta2roberta_L-24_bbc\")\n",
    "\n",
    "article = \"\"\"The problem is affecting people using the older\n",
    "versions of the PlayStation 3, called the \"Fat\"\n",
    "model.The problem isn't affecting the newer PS3\n",
    "Slim systems that have been on sale since\n",
    "September last year.Sony have also said they are\n",
    "aiming to have the problem fixed shortly but is\n",
    "advising some users to avoid using their console\n",
    "for the time being.\"We hope to resolve this\n",
    "problem within the next 24 hours,\" a statement\n",
    "reads. \"In the meantime, if you have a model other\n",
    "than the new slim PS3, we advise that you do not\n",
    "use your PS3 system, as doing so may result in\n",
    "errors in some functionality, such as recording\n",
    "obtained trophies, and not being able to restore\n",
    "certain data.\"We believe we have identified that\n",
    "this problem is being caused by a bug in the clock\n",
    "functionality incorporated in the system.\"The\n",
    "PlayStation Network is used by millions of people\n",
    "around the world.It allows users to play their\n",
    "friends at games like Fifa over the internet and\n",
    "also do things like download software or visit\n",
    "online stores.\"\"\"\n",
    "\n",
    "input_ids = tokenizer(article, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "print(tokenizer.decode(output_ids, skip_special_tokens=True))\n",
    "# should output\n",
    "# Some Sony PlayStation gamers are being advised to stay away from the network because of a problem with the PlayStation 3 network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f02733710020074"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from transformers import pipeline\n",
    "\n",
    "# Read PDF document and extract the text from a range of pages.\n",
    "def extract_text_from_pdf(pdf_path, start_page=None, end_page=None):\n",
    "    return extract_text(pdf_path, page_numbers=range(start_page, end_page+1) if start_page and end_page else None)\n",
    "\n",
    "# Usage\n",
    "pdf_path = '../data/CACM\\'18_Search-based_Program_Synthesis.pdf'\n",
    "extracted_text = extract_text_from_pdf(pdf_path, 1, 8)\n",
    "# Initialize the HuggingFace summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"MBZUAI/LaMini-Flan-T5-248M\")\n",
    "# Run summarization\n",
    "summary = summarizer(extracted_text[0:2350], max_length=350, min_length=25, do_sample=False)\n",
    "# Print summary\n",
    "print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de972c2171166022"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
